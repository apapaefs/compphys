{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bde0176-c1a1-4a30-8482-2ddfb8e10b3f",
   "metadata": {},
   "source": [
    "# More Monte Carlo: The Metropolis Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f539848-f48d-48ec-bfb2-1737120b51b6",
   "metadata": {},
   "source": [
    "## The Algorithm of Metropolis et al.\n",
    "\n",
    "We have already discussed algorithms for generating random numbers according to a specified distribution (e.g. via von Neumann rejection). \n",
    "\n",
    "However, it is difficult, or impossible, to generalize them to sample a complicated weight function in many dimensions, and so an alternate approach is required. \n",
    "\n",
    "A very general way to produce random variables with a given probability distribution of arbitrary form is the algorithm of Metropolis, Rosenbluth, Rosenbluth, Teller and Teller (https://doi.org/10.1063/1.1699114).\n",
    "\n",
    "This algorithm requires only the ability to calculate the weight function for a given value of the integration variable. \n",
    "\n",
    "It proceeds as follows: Suppose we want to generate a set of points in a possibly multi-dimensional space of variables, $\\mathbf{X}$, distributed with probability density $w(\\mathbf{X})$. \n",
    "\n",
    "The Metropolis et al. algorithm generates a sequence of points:\n",
    "\n",
    "$\\mathbf{X}_0, \\mathbf{X}_1, ...$, \n",
    "\n",
    "as those visited successively by a random walker moving through $\\mathbf{X}$ space. \n",
    "\n",
    "As the walk gets longer and longer, the points it connects approximate more closely the desired distribution. \n",
    "\n",
    "The rules of the random walk through configuration space are as follows:\n",
    "\n",
    "- Suppose a random walker is at point $\\mathbf{X}_n$ in the sequence.\n",
    "- To generate $\\mathbf{X}_{n+1}$, it makes a *trial step* to a new point, $\\mathbf{X}_t$.\n",
    "- This new point can be chosen in any convenient manner, e.g. uniformly at random within a multi-dimensional cube of small size $\\delta$ about $\\mathbf{X}_n$.\n",
    "- The trial step is then \"accepted\" or \"rejected\" according to the ratio:\n",
    "\n",
    "$ r = \\frac{ w(\\mathbf{X}_t) } { w(\\mathbf{X}_n) }$.\n",
    "\n",
    "If $r>1$ then the step is accepted and we set $\\mathbf{X}_{n+1} = \\mathbf{X}_t$, while if $r<1$, the step is accepted with probability $r$.  \n",
    "\n",
    "This is accomplished by comparing $r$ with a random number $\\eta$, uniformly distributed in $[0,1]$, and accepting the step if $\\eta < r$. \n",
    "\n",
    "If the trial step is not accepted, then it is rejected and we put $\\mathbf{X}_{n+1} = \\mathbf{X}_n$.\n",
    "- This generates $\\mathbf{X}_{n+1}$, and we may then proceed to generate $\\mathbf{X}_{n+2}$ by the same process, making a trial step from $\\mathbf{X}_{n+1}$.\n",
    "- Any arbitrary point $\\mathbf{X}_0$ can be chosen as the starting point for the random walk.\n",
    "- During this process, the code could be made more efficient by saving the weight function at the current point of the random walk, so that it need not be computed again when deciding whether or not to accept the trial step. The evaluation of $w$ is often the most time-consuming part of a Monte Carlo calculation using the Metropolis et al. algorithm.\n",
    "\n",
    "## Proof of the Metropolis et al. Algorithm\n",
    "\n",
    "To prove that the algorithm does indeed generate a sequence of points distributed according to $w$, let us consider a large number of walkers, starting from different initial points and moving independently through $\\mathbf{X}$ space. \n",
    "\n",
    "If $N_n(\\mathbf{X})$ is the density of walkers at $\\mathbf{X}$ after $n$ steps, then the net number of walkers moving from point $\\mathbf{X}$ to a point $\\mathbf{Y}$ in the next step is: \n",
    "\n",
    "$\\Delta N(\\mathbf{X}) = N_n(\\mathbf{X}) P(\\mathbf{X} \\rightarrow \\mathbf{Y}) - N_n(\\mathbf{Y}) P(\\mathbf{Y} \\rightarrow \\mathbf{X})$,\n",
    "\n",
    "where $P(\\mathbf{X} \\rightarrow \\mathbf{Y})$ is the probability that a walker will make a transition to $\\mathbf{Y}$ if it is at $\\mathbf{X}$. \n",
    "\n",
    "\n",
    "Taking out a common factor $N_n (\\mathbf{Y}) P(\\mathbf{X} \\rightarrow \\mathbf{Y})$:\n",
    "\n",
    "$\\Delta N(\\mathbf{X}) = N_n (\\mathbf{Y}) P(\\mathbf{X} \\rightarrow \\mathbf{Y}) \\left[ \\frac{ N_n(\\mathbf{X})}{N_n (\\mathbf{Y})} - \\frac{P(\\mathbf{Y} \\rightarrow \\mathbf{X})}{P(\\mathbf{X} \\rightarrow \\mathbf{Y})}\\right]$.\n",
    "\n",
    "The above shows that there is equilibrium, corresponding to no net population change, when:\n",
    "\n",
    "$\\frac{ N_n(\\mathbf{X})}{N_n (\\mathbf{Y})} = \\frac{ N_e(\\mathbf{X})}{N_e (\\mathbf{Y})} \\equiv \\frac{P(\\mathbf{Y} \\rightarrow \\mathbf{X})}{P(\\mathbf{X} \\rightarrow \\mathbf{Y})}$,\n",
    "\n",
    "and that changes in $N(\\mathbf{X})$ when the system is not in equilibrium tend to drive it toward equilibrium, i.e. $\\Delta N(\\mathbf{X}) > 0$ if there are \"too many walkers\" at $\\mathbf{X}$, or if $N_n(\\mathbf{X})/N_n(\\mathbf{Y})$ is greater than its equilbrium value. \n",
    "\n",
    "Hence it is possible, and it can be shown, that after a large number of steps, the population of the walkers will settle down to its equilibrium distribution $N_e$. \n",
    "\n",
    "What remains to be shown is that the transition probabilities of the algorithm lead to an equilibrium distribution of walkers $N_e(\\mathbf{X}) \\sim w(\\mathbf{X})$.\n",
    "\n",
    "The probability of making a step from $\\mathbf{X}$ to $\\mathbf{Y}$ is:\n",
    "\n",
    "$P(\\mathbf{X} \\rightarrow \\mathbf{Y}) = T(\\mathbf{X} \\rightarrow \\mathbf{Y}) A (\\mathbf{X} \\rightarrow \\mathbf{Y})$, \n",
    "\n",
    "where $T$ is the probability of making a trial step from $\\mathbf{X}$ to $\\mathbf{Y}$, and $A$ is the probability of accepting that step. \n",
    "\n",
    "If $\\mathbf{Y}$ can be reached from $\\mathbf{X}$ in a single step (i.e. if it is within a cube of side $\\delta$, centered about $\\mathbf{X}$), then:\n",
    "\n",
    "$T(\\mathbf{X} \\rightarrow \\mathbf{Y}) = T(\\mathbf{Y} \\rightarrow \\mathbf{X})$. \n",
    "\n",
    "so that the equilibrium distribution of the random walkers satisfies:\n",
    "\n",
    "$\\frac{ N_e(\\mathbf{X})}{N_e (\\mathbf{Y})} = \\frac{A(\\mathbf{Y} \\rightarrow \\mathbf{X})}{A(\\mathbf{X} \\rightarrow \\mathbf{Y})}$.\n",
    "\n",
    "Now, there are two scenarios for the ratio between $w$'s at $\\mathbf{X}$ and $\\mathbf{Y}$: \n",
    "\n",
    "if $w(\\mathbf{X}) > w(\\mathbf{Y})$, then $A(\\mathbf{Y} \\rightarrow \\mathbf{X}) = 1$, and:\n",
    "\n",
    "$A(\\mathbf{X} \\rightarrow \\mathbf{Y}) = \\frac{ w(\\mathbf{Y}) } {w(\\mathbf{X})}$,\n",
    "\n",
    "while if $w(\\mathbf{X}) < w(\\mathbf{Y})$, then $A(\\mathbf{X} \\rightarrow \\mathbf{Y}) = 1$\n",
    "\n",
    "$A(\\mathbf{Y} \\rightarrow \\mathbf{X}) = \\frac{ w(\\mathbf{X}) } {w(\\mathbf{Y})}$.\n",
    "\n",
    "Hence, in either case, the equilibrium population of the walkers satisfies:\n",
    "\n",
    "$\\frac{ N_e(\\mathbf{X})}{N_e (\\mathbf{Y})} = \\frac{ w(\\mathbf{X})}{w(\\mathbf{Y})}$,\n",
    "\n",
    "so that the walkers are indeed distributed with the correct distribution. \n",
    "\n",
    "## Applying the Metropolis et al. Algorithm\n",
    "\n",
    "An obvious question is, how do we choose the step size, $\\delta$?\n",
    "\n",
    "To answer this, suppose that $\\mathbf{X}_n$ is at a maximum of $w$, the most likely place for it to be. If $\\delta$ is large, then $w(\\mathbf{X}_t)$ will likely be very much smaller than $w(\\mathbf{X}_n)$, and most trial steps will be rejected, leading to an inefficient sampling of $w$. If $\\delta$ is very small, most trial steps will be accepted, but the random walker will never move very far, and so also lead to a poor sampling of the distribution. \n",
    "\n",
    "A good rule of thumb is that the size of the trial step should be chosen so that about half of the trial steps are accepted. \n",
    "\n",
    "One bane of applying the algorithm to sample a distribution is that the points that make up the random walk $\\mathbf{X}_0, \\mathbf{X}_1, ...$ are *not independent* of one another, simply from the way in which they are generated. That is, $\\mathbf{X}_{n+1}$ is likely to be in the neighborhood of $\\mathbf{X}_n$. Thus, while the points might be distributed properly as the walk becomes very long, they are not statistically independent of one another.\n",
    "\n",
    "This dictates that some care should be taken in using them to, e.g., calculate integrals. \n",
    "\n",
    "For example, suppose we wish to calculate:\n",
    "\n",
    "$I = \\int \\mathrm{d} \\mathbf{X} w(\\mathbf{X}) f(\\mathbf{X})$, \n",
    "\n",
    "where $w(\\mathbf{X})$ is the normalized weight function. \n",
    "\n",
    "e.g. in one dimension:\n",
    "\n",
    "$I = \\int \\mathrm{d} x w(x) f(x)$, and change variables to $y$, with $\\mathrm{d}y/\\mathrm{d}x = w(x)$ to get $I = \\int \\mathrm{d} y f(x(y))$. \n",
    "\n",
    "We would do this by averaging the values of $f$ over the points of the random walk. However, the usual estimate of the variance is invalid, because the $f(\\mathbf{X}_i)$ are *not* statistically independent.\n",
    "\n",
    "The level of statistical dependence can be quantified by calculating the auto-correlation function:\n",
    "\n",
    "$C(k) = \\frac{ \\left< f_i f_{i+k} \\right> - \\left< f_i \\right>^2 } { \\left< f_i^2 \\right> - \\left< f_i \\right>^2 }$,\n",
    "\n",
    "where $\\left<...\\right>$ indicates average over the random walk, e.g.:\n",
    "\n",
    "$\\left< f_i f_{i+k} \\right> = \\frac{1}{N-k} \\sum_{i=1}^{N-k} f(\\mathbf{X}_i) f(\\mathbf{X}_{i+k})$.\n",
    "\n",
    "The non-vanishing of $C$ for $k\\neq 0$ means that the $f$'s are *not* independent.\n",
    "\n",
    "What can be done in practice is to compute the integral and its variance using points along the random walk separated by a fixed interval, the interval being chosen so that there is effectively no correlation between the points used. An appropriate sampling interval can be estimated from the value of $k$ for which becomes small, e.g., say $C\\lesssim  0.1$.\n",
    "\n",
    "Another issue in applying the algorithm is where to start the random walk, i.e. what to take as $\\mathbf{X}_0$. In principle any location is suitable and the results will be independent of this choice, as the walker will \"thermalize\" after some number of steps. In practice, an appropriate starting point is a probable one, where $w$ is large. Some number of thermalization steps then can be taken before actual sampling begins to remove any dependence on the starting point. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8297a011-3fa9-4bb7-842a-f3f141eafdb0",
   "metadata": {},
   "source": [
    "## Example 11.1: The Metropolis Algorithm for One-dimensional Integration\n",
    "\n",
    "(a) Use the algorithm of Metropolis et. al to sample the normal distribution in one dimension:\n",
    "\n",
    "$w(x) = e^{-x^2/2}/\\sqrt{2\\pi}$.\n",
    "\n",
    "For various step sizes, study the acceptance ratio (i.e. the fraction of trial steps accepted), the correlation function (and hence the appropriate sampling frequency), and the overall computational efficiency. \n",
    "\n",
    "(b) Use the random variables you generate to calculate the integral: \n",
    "\n",
    "$I = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty} \\mathrm{d}x x^2 e^{-x^2/2}$, \n",
    "\n",
    "and estimate the uncertainty in your answer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade51770-d334-4773-b433-c6f53a9a6b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
